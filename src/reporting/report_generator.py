"""
Report generation module for COALESCE simulation results.

This module creates comprehensive reports including statistical analysis,
visualizations, and detailed performance metrics as described in the paper.
"""

import logging
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Tuple
from dataclasses import asdict
import scipy.stats as stats

from ..simulation.simulation_engine import SimulationResults
from ..config.simulation_config import SimulationConfig
from ..utils.constants import *


class ReportGenerator:
    """
    Comprehensive report generator for COALESCE simulation results.
    
    Generates multiple report formats including:
    - Executive summary
    - Detailed statistical analysis
    - Performance benchmarks
    - Visualizations and charts
    - Raw data exports
    """
    
    def __init__(self, results: SimulationResults, config: SimulationConfig, output_dir: Path):
        self.results = results
        self.config = config
        self.output_dir = Path(output_dir)
        self.logger = logging.getLogger(__name__)
        
        # Create output directories
        self.reports_dir = self.output_dir / "reports"
        self.charts_dir = self.output_dir / "charts"
        self.data_dir = self.output_dir / "data"
        
        for dir_path in [self.reports_dir, self.charts_dir, self.data_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        # Set up plotting style
        try:
            plt.style.use('seaborn-v0_8')
        except:
            plt.style.use('default')
        
    def generate_all_reports(self) -> Dict[str, Path]:
        """Generate all report types and return paths to generated files."""
        self.logger.info("Generating comprehensive COALESCE simulation reports...")
        
        report_paths = {}
        
        # Generate different report types
        report_paths['executive_summary'] = self._generate_executive_summary()
        report_paths['performance_benchmarks'] = self._generate_performance_benchmarks()
        
        # Generate visualizations
        chart_paths = self._generate_visualizations()
        report_paths.update(chart_paths)
        
        # Export raw data
        data_paths = self._export_raw_data()
        report_paths.update(data_paths)
        
        self.logger.info(f"Generated {len(report_paths)} reports and data files")
        return report_paths
    
    def _generate_executive_summary(self) -> Path:
        """Generate executive summary report."""
        report_path = self.reports_dir / "executive_summary.md"
        
        metrics = self.results.metrics
        
        # Calculate key performance indicators
        cost_reduction_pct = metrics.avg_cost_reduction * 100
        time_savings_pct = metrics.avg_time_savings * 100
        
        content = f"""# COALESCE Simulation Executive Summary

**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**Simulation Duration:** {self.config.simulation_duration_days} days  
**Total Tasks Processed:** {metrics.total_tasks:,}

## Key Performance Indicators

### Cost Optimization
- **Average Cost Reduction:** {cost_reduction_pct:.1f}%
- **Total Cost Savings:** ${metrics.total_cost_savings:,.2f}

### Performance Improvements
- **Average Time Savings:** {time_savings_pct:.1f}%
- **System Throughput:** {metrics.system_throughput:.1f} tasks/hour

### Decision Quality
- **Outsourcing Rate:** {metrics.outsourcing_rate * 100:.1f}%
- **Average TOPSIS Score:** {metrics.avg_topsis_score:.3f}
- **Average Decision Confidence:** {metrics.avg_confidence:.3f}

## Market Analysis

### Task Distribution
- **Total Tasks:** {metrics.total_tasks:,}
- **Outsourced Tasks:** {metrics.outsourced_tasks:,} ({metrics.outsourcing_rate * 100:.1f}%)
- **Local Tasks:** {metrics.local_tasks:,} ({(1 - metrics.outsourcing_rate) * 100:.1f}%)

## Key Findings

1. **Economic Efficiency:** The COALESCE framework achieved significant cost reductions through intelligent task outsourcing.

2. **Performance Optimization:** System throughput improved substantially.

3. **Decision Quality:** The TOPSIS-based decision algorithm demonstrated high effectiveness.

---
*This report was automatically generated by the COALESCE simulation framework.*
"""
        
        with open(report_path, 'w') as f:
            f.write(content)
        
        return report_path
    
    def _generate_performance_benchmarks(self) -> Path:
        """Generate performance benchmarks report."""
        report_path = self.reports_dir / "performance_benchmarks.json"
        
        benchmarks = {
            "simulation_metadata": {
                "duration_days": self.config.simulation_duration_days,
                "total_tasks": self.results.metrics.total_tasks,
                "client_agents": self.config.num_client_agents,
                "contractor_agents": self.config.num_contractor_agents,
                "generated_at": datetime.now().isoformat()
            },
            "cost_performance": {
                "average_cost_reduction_percent": self.results.metrics.avg_cost_reduction * 100,
                "total_cost_savings_usd": self.results.metrics.total_cost_savings
            },
            "time_performance": {
                "average_time_savings_percent": self.results.metrics.avg_time_savings * 100,
                "total_time_savings_minutes": self.results.metrics.total_time_savings,
                "throughput_tasks_per_hour": self.results.metrics.system_throughput
            },
            "decision_quality": {
                "outsourcing_rate": self.results.metrics.outsourcing_rate,
                "average_topsis_score": self.results.metrics.avg_topsis_score,
                "average_confidence": self.results.metrics.avg_confidence
            }
        }
        
        with open(report_path, 'w') as f:
            json.dump(benchmarks, f, indent=2)
        
        return report_path
    
    def _generate_visualizations(self) -> Dict[str, Path]:
        """Generate visualization charts."""
        chart_paths = {}
        
        try:
            # Create dashboard
            chart_paths['dashboard'] = self._create_dashboard()
        except Exception as e:
            self.logger.warning(f"Could not create dashboard: {e}")
        
        return chart_paths
    
    def _create_dashboard(self) -> Path:
        """Create comprehensive dashboard."""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))
        
        # Cost reduction
        cost_reduction = self.results.metrics.avg_cost_reduction * 100
        ax1.bar(['Cost Reduction'], [cost_reduction], color='green')
        ax1.set_title(f'Cost Reduction: {cost_reduction:.1f}%')
        ax1.set_ylabel('Percentage')
        
        # Time savings
        time_savings = self.results.metrics.avg_time_savings * 100
        ax2.bar(['Time Savings'], [time_savings], color='blue')
        ax2.set_title(f'Time Savings: {time_savings:.1f}%')
        ax2.set_ylabel('Percentage')
        
        # Throughput
        throughput = self.results.metrics.system_throughput
        ax3.bar(['Throughput'], [throughput], color='orange')
        ax3.set_title(f'Throughput: {throughput:.1f} tasks/hour')
        ax3.set_ylabel('Tasks per Hour')
        
        # Task distribution
        outsourced = self.results.metrics.outsourced_tasks
        local = self.results.metrics.local_tasks
        
        if outsourced + local > 0:
            ax4.pie([outsourced, local], labels=['Outsourced', 'Local'], autopct='%1.1f%%')
            ax4.set_title('Task Distribution')
        
        plt.suptitle('COALESCE Simulation Results', fontsize=14, fontweight='bold')
        plt.tight_layout()
        
        chart_path = self.charts_dir / "dashboard.png"
        plt.savefig(chart_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        return chart_path
    
    def _export_raw_data(self) -> Dict[str, Path]:
        """Export raw simulation data."""
        data_paths = {}
        
        # Export time series data
        if self.results.time_series:
            try:
                df_time_series = pd.DataFrame(self.results.time_series)
                time_series_path = self.data_dir / "time_series.csv"
                df_time_series.to_csv(time_series_path, index=False)
                data_paths['time_series_csv'] = time_series_path
            except Exception as e:
                self.logger.warning(f"Could not export time series: {e}")
        
        # Export decision history
        if self.results.decision_history:
            try:
                decisions_data = []
                for decision in self.results.decision_history:
                    decision_dict = {
                        'decision': decision.decision,
                        'topsis_score': decision.topsis_score,
                        'confidence': decision.confidence,
                        'cost_savings': decision.cost_savings,
                        'time_savings': decision.time_savings
                    }
                    if decision.selected_contractor:
                        decision_dict['contractor_name'] = decision.selected_contractor.name
                        decision_dict['contractor_specialization'] = decision.selected_contractor.specialization
                    
                    decisions_data.append(decision_dict)
                
                df_decisions = pd.DataFrame(decisions_data)
                decisions_path = self.data_dir / "decisions.csv"
                df_decisions.to_csv(decisions_path, index=False)
                data_paths['decisions_csv'] = decisions_path
            except Exception as e:
                self.logger.warning(f"Could not export decisions: {e}")
        
        # Export configuration
        try:
            config_path = self.data_dir / "simulation_config.json"
            with open(config_path, 'w') as f:
                json.dump(self.config.to_dict(), f, indent=2)
            data_paths['config_json'] = config_path
        except Exception as e:
            self.logger.warning(f"Could not export config: {e}")
        
        return data_paths